<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Victoria Drake, Director of Engineering, is building better cybersecurity and happy and productive technical teams."><title>Multithreaded Python: slithering through an I/O bottleneck | victoria.dev</title><link href=https://github.com/victoriadrake rel=me><link rel=authorization_endpoint href=https://indieauth.com/auth><link rel=token_endpoint href=https://tokens.indieauth.com/token><link rel=webmention href=https://webmention.io/victoria.dev/webmention><link rel=pingback href=https://webmention.io/victoria.dev/xmlrpc><link rel=feed href=https://victoria.dev/neofeed><script async defer data-domain=victoria.dev src=https://p.victoria.dev/js/index.js></script><meta name=monetization content="$ilp.uphold.com/pBRfRwg2EJAe"><meta property="og:title" content="Multithreaded Python: slithering through an I/O bottleneck - victoria.dev"><meta property="og:type" content="website"><meta property="og:description" content="How taking advantage of parallelism in Python can make your software orders of magnitude faster."><meta property="og:url" content="https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/"><meta property="og:site_name" content="victoria.dev"><meta property="og:image" content="https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Multithreaded Python: slithering through an I/O bottleneck"><meta name=twitter:image content="https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/cover.png"><meta name=twitter:description content="How taking advantage of parallelism in Python can make your software orders of magnitude faster."><link rel="shortcut icon" href=/img/favicon.ico><link rel=stylesheet href=/css/main.min.937c4fda6130169948d504600cae0e8115a92fcf1ce7a80e51dc971049c29779.css integrity="sha256-k3xP2mEwFplI1QRgDK4OgRWpL88c56gOUdyXEEnCl3k=" media=screen></head><body><header role=banner><nav aria-label="Victoria.dev main menu" id=menu><ul role=menubar><li role=none class=menu-item><a role=menuitem href=/><img src=/img/bookmark.svg alt="home page icon" height=18px class=filter-icon> hi</a></li><li role=none class=menu-item><a role=menuitem href=/blog/><img src=/img/quote.svg alt="blog icon" height=18px class=filter-icon> blog</a></li><li role=none class=menu-item><a role=menuitem href=/about/><img src=/img/profile.svg alt="about page icon" height=18px class=filter-icon> about</a></li><li role=none class=menu-item><a role=menuitem href=/coffee/><img src=/img/coffee.svg alt="coffee icon" height=18px class=filter-icon> buy me coffee</a></li><li role=none class=menu-item><a role=menuitem href=/bookshelf/><img src=/img/book.svg alt="bookshelf icon" height=18px class=filter-icon> bookshelf</a></li><li role=none class=menu-item><a role=menuitem id=rss href=https://victoria.dev/index.xml rel=alternate type=application/rss+xml title="RSS for Multithreaded Python: slithering through an I/O bottleneck"><img src=/img/rss.svg alt="RSS icon" height=18px class=filter-icon> rss</a></li></ul></nav></header><main aria-role=main><div class=container><div id=cover-image><img src=https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/cover.png alt="cover image"></div><article><h1>Multithreaded Python: slithering through an I/O bottleneck</h1><p class=subtitle>How taking advantage of parallelism in Python can make your software orders of magnitude faster.</p><span><a class="tag button" href=/tags/python/>python
</a>&nbsp;
<a class="tag button" href=/tags/computing/>computing
</a>&nbsp;
<a class="tag button" href=/tags/ci/cd/>ci/cd
</a>&nbsp;
<a class="tag button" href=/tags/data/>data
</a>&nbsp;
<a class="tag button" href=/tags/open-source/>open-source
</a>&nbsp;</span><p class=metadata id=date><time><a class="u-url dt-published" href=https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/>February 28, 2020</a></time>
<span class=dt-updated>&nbsp;
<em>Updated: Mar 1, 2021</em></span>
<span>☕️&nbsp;5 min read</span></p></p><div class=page-separator><hr></div><div class="markdown e-content"><p>I recently developed a project that I called <a href=https://github.com/victoriadrake/hydra-link-checker>Hydra</a>: a multithreaded link checker written in Python. Unlike many Python site crawlers I found while researching, Hydra uses only standard libraries, with no external dependencies like BeautifulSoup. It&rsquo;s intended to be run as part of a CI/CD process, so part of its success depended on being fast.</p><p>Multiple threads in Python is a bit of a bitey subject (not sorry) in that the Python interpreter doesn&rsquo;t actually let multiple threads execute at the same time. Python&rsquo;s <a href=https://wiki.python.org/moin/GlobalInterpreterLock>Global Interpreter Lock</a>, or GIL, prevents multiple threads from executing Python bytecodes at once. Each thread that wants to execute must first wait for the GIL to be released by the currently executing thread. The GIL is pretty much the microphone in a low-budget conference panel, except where no one gets to shout.</p><p>This has the advantage of preventing <a href=https://en.wikipedia.org/wiki/Race_condition>race conditions</a>. It does, however, lack the performance advantages afforded by running multiple tasks in parallel. (If you&rsquo;d like a refresher on concurrency, parallelism, and multithreading, see <a href=/blog/concurrency-parallelism-and-the-many-threads-of-santa-claus/>Concurrency, parallelism, and the many threads of Santa Claus</a>.) While I prefer Go for its convenient first-class primitives that support concurrency (see <a href=https://tour.golang.org/concurrency/1>Goroutines</a>), this project&rsquo;s recipients were more comfortable with Python. I took it as an opportunity to test and explore!</p><p>Simultaneously performing multiple tasks in Python isn&rsquo;t impossible; it just takes a little extra work. For Hydra, the main advantage is in overcoming the input/output (I/O) bottleneck.</p><p>In order to get web pages to check, Hydra needs to go out to the Internet and fetch them. When compared to tasks that are performed by the CPU alone, going out over the network is comparatively slower. How slow?</p><p>Here are approximate timings for tasks performed on a typical PC:</p><table><thead><tr><th></th><th>Task</th><th>Time</th></tr></thead><tbody><tr><td>CPU</td><td>execute typical instruction</td><td>1/1,000,000,000 sec = 1 nanosec</td></tr><tr><td>CPU</td><td>fetch from L1 cache memory</td><td>0.5 nanosec</td></tr><tr><td>CPU</td><td>branch misprediction</td><td>5 nanosec</td></tr><tr><td>CPU</td><td>fetch from L2 cache memory</td><td>7 nanosec</td></tr><tr><td>RAM</td><td>Mutex lock/unlock</td><td>25 nanosec</td></tr><tr><td>RAM</td><td>fetch from main memory</td><td>100 nanosec</td></tr><tr><td>Network</td><td>send 2K bytes over 1Gbps network</td><td>20,000 nanosec</td></tr><tr><td>RAM</td><td>read 1MB sequentially from memory</td><td>250,000 nanosec</td></tr><tr><td>Disk</td><td>fetch from new disk location (seek)</td><td>8,000,000 nanosec (8ms)</td></tr><tr><td>Disk</td><td>read 1MB sequentially from disk</td><td>20,000,000 nanosec (20ms)</td></tr><tr><td>Network</td><td>send packet US to Europe and back</td><td>150,000,000 nanosec (150ms)</td></tr></tbody></table><p>Peter Norvig first published these numbers some years ago in <a href=http://norvig.com/21-days.html#answers>Teach Yourself Programming in Ten Years</a>. Since computers and their components change year over year, the exact numbers shown above aren&rsquo;t the point. What these numbers help to illustrate is the difference, in orders of magnitude, between operations.</p><p>Compare the difference between fetching from main memory and sending a simple packet over the Internet. While both these operations occur in less than the blink of an eye (literally) from a human perspective, you can see that sending a simple packet over the Internet is over a million times slower than fetching from RAM. It&rsquo;s a difference that, in a single-thread program, can quickly accumulate to form troublesome bottlenecks.</p><p>In Hydra, the task of parsing response data and assembling results into a report is relatively fast, since it all happens on the CPU. The slowest portion of the program&rsquo;s execution, by over six orders of magnitude, is network latency. Not only does Hydra need to fetch packets, but whole web pages! One way of improving Hydra&rsquo;s performance is to find a way for the page fetching tasks to execute without blocking the main thread.</p><p>Python has a couple options for doing tasks in parallel: multiple processes, or multiple threads. These methods allow you to circumvent the GIL and speed up execution in a couple different ways.</p><h2 id=multiple-processes class=anchor-link><a href=https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/#multiple-processes>Multiple processes</a></h2><p>To execute parallel tasks using multiple processes, you can use Python&rsquo;s <a href=https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor><code>ProcessPoolExecutor</code></a>. A concrete subclass of <a href=https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor><code>Executor</code></a> from the <a href=https://docs.python.org/3/library/concurrent.futures.html><code>concurrent.futures</code> module</a>, <code>ProcessPoolExecutor</code> uses a pool of processes spawned with the <a href=https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing><code>multiprocessing</code> module</a> to avoid the GIL.</p><p>This option uses worker subprocesses that maximally default to the number of processors on the machine. The <code>multiprocessing</code> module allows you to maximally parallelize function execution across processes, which can really speed up compute-bound (or <a href=https://en.wikipedia.org/wiki/CPU-bound>CPU-bound</a>) tasks.</p><p>Since the main bottleneck for Hydra is I/O and not the processing to be done by the CPU, I&rsquo;m better served by using multiple threads.</p><h2 id=multiple-threads class=anchor-link><a href=https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/#multiple-threads>Multiple threads</a></h2><p>Fittingly named, Python&rsquo;s <a href=https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor><code>ThreadPoolExecutor</code></a> uses a pool of threads to execute asynchronous tasks. Also a subclass of <a href=https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor><code>Executor</code></a>, it uses a defined number of maximum worker threads (at least five by default, according to the formula <code>min(32, os.cpu_count() + 4)</code>) and reuses idle threads before starting new ones, making it pretty efficient.</p><p>Here is a snippet of Hydra with comments showing how Hydra uses <code>ThreadPoolExecutor</code> to achieve parallel multithreaded bliss:</p><div class=highlight><pre class=chroma><code class=language-py data-lang=py><span class=c1># Create the Checker class</span>
<span class=k>class</span> <span class=nc>Checker</span><span class=p>:</span>
    <span class=c1># Queue of links to be checked</span>
    <span class=n>TO_PROCESS</span> <span class=o>=</span> <span class=n>Queue</span><span class=p>()</span>
    <span class=c1># Maximum workers to run</span>
    <span class=n>THREADS</span> <span class=o>=</span> <span class=mi>100</span>
    <span class=c1># Maximum seconds to wait for HTTP response</span>
    <span class=n>TIMEOUT</span> <span class=o>=</span> <span class=mi>60</span>

    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>url</span><span class=p>):</span>
        <span class=o>...</span>
        <span class=c1># Create the thread pool</span>
        <span class=bp>self</span><span class=o>.</span><span class=n>pool</span> <span class=o>=</span> <span class=n>futures</span><span class=o>.</span><span class=n>ThreadPoolExecutor</span><span class=p>(</span><span class=n>max_workers</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>THREADS</span><span class=p>)</span>


<span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
    <span class=c1># Run until the TO_PROCESS queue is empty</span>
    <span class=k>while</span> <span class=bp>True</span><span class=p>:</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>target_url</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>TO_PROCESS</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>block</span><span class=o>=</span><span class=bp>True</span><span class=p>,</span> <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
            <span class=c1># If we haven&#39;t already checked this link</span>
            <span class=k>if</span> <span class=n>target_url</span><span class=p>[</span><span class=s2>&#34;url&#34;</span><span class=p>]</span> <span class=ow>not</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>visited</span><span class=p>:</span>
                <span class=c1># Mark it as visited</span>
                <span class=bp>self</span><span class=o>.</span><span class=n>visited</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>target_url</span><span class=p>[</span><span class=s2>&#34;url&#34;</span><span class=p>])</span>
                <span class=c1># Submit the link to the pool</span>
                <span class=n>job</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool</span><span class=o>.</span><span class=n>submit</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>load_url</span><span class=p>,</span> <span class=n>target_url</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>TIMEOUT</span><span class=p>)</span>
                <span class=n>job</span><span class=o>.</span><span class=n>add_done_callback</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>handle_future</span><span class=p>)</span>
        <span class=k>except</span> <span class=n>Empty</span><span class=p>:</span>
            <span class=k>return</span>
        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=k>print</span><span class=p>(</span><span class=n>e</span><span class=p>)</span>
</code></pre></div><p>You can view the full code in <a href=https://github.com/victoriadrake/hydra-link-checker>Hydra&rsquo;s GitHub repository</a>.</p><h2 id=single-thread-to-multithread class=anchor-link><a href=https://victoria.dev/blog/multithreaded-python-slithering-through-an-i/o-bottleneck/#single-thread-to-multithread>Single thread to multithread</a></h2><p>If you&rsquo;d like to see the full effect, I compared the run times for checking my website between a prototype single-thread program, and the <del>multiheaded</del>multithreaded Hydra.</p><div class=highlight><pre class=chroma><code class=language-text data-lang=text>time python3 slow-link-check.py https://victoria.dev

real    17m34.084s
user    11m40.761s
sys     0m5.436s


time python3 hydra.py https://victoria.dev

real    0m15.729s
user    0m11.071s
sys     0m2.526s
</code></pre></div><p>The single-thread program, which blocks on I/O, ran in about seventeen minutes. When I first ran the multithreaded version, it finished in 1m13.358s - after some profiling and tuning, it took a little under sixteen seconds. Again, the exact times don&rsquo;t mean all that much; they&rsquo;ll vary depending on factors such as the size of the site being crawled, your network speed, and your program&rsquo;s balance between the overhead of thread management and the benefits of parallelism.</p><p>The more important thing, and the result I&rsquo;ll take any day, is a program that runs some orders of magnitude faster.</p></div><a class=hidden href=https://brid.gy/publish/twitter></a><a class=hidden href=https://brid.gy/publish/mastodon></a><data class=p-bridgy-omit-link value=false></data></article><div id=up-container><a href=# id=up>&#709;</a></div><div class=page-separator><hr></div><div id=webmentions></div><div class=related><code class=language-sql data-lang=sql>SELECT TOP 3 * FROM Related;</code><ul role=menubar id=article-list><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/breaking-bottlenecks/>Breaking bottlenecks 🍾</a><p class=e-content>A talk on the benefits of non-blocking functions for programs, developers, and organizations.</p><p class=metadata><a class="tag button" href=/tags/computing/>computing</a>
☕️ ☕️ ☕️
&nbsp;12 min read
<time class="hidden dt-published">2020-02-25 12:50:29 -0500 -0500</time></p></li><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/what-is-tcp/ip-layers-and-protocols-explained/>What is TCP/IP? Layers and protocols explained</a><p class=e-content>Alternatively titled, "Why the Internet Protocol Suite is an imaginary rainbow layer cake"</p><p class=metadata><a class="tag button" href=/tags/computing/>computing</a>
☕️
&nbsp;5 min read
<time class="hidden dt-published">2020-11-29 04:01:22 -0400 -0400</time></p></li><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/manipulating-data-with-django-migrations/>Manipulating data with Django migrations</a><p class=e-content>How to update Django models and manipulate existing data using migrations.</p><p class=metadata><a class="tag button" href=/tags/coding/>coding</a>
☕️
&nbsp;5 min read
<time class="hidden dt-published">2020-09-14 02:12:57 -0400 -0400</time></p></li></ul><div class=page-separator><p class=back-link><a href=/blog>&lt;&lt; Back to blog</a></p></div></div></div><footer class=container><div class="markdown bio h-card p-author"><strong><a href=https://victoria.dev/ class="u-url p-name">Victoria Drake</a></strong><figure class="profile title-avatar u-photo"><img src=/img/victoria_headshot.jpg alt="Victoria's headshot"></figure><p>Victoria Drake is a Director of Engineering in Washington, DC. She is a core maintainer and co-author for the Open Web Application Security Project (OWASP) Web Security Testing Guide. She earned the annual Top Contributor award three years in a row from the freeCodeCamp non-profit, and is a recognized Distinguished Author on the DEV.to developer platform. She writes about software development, cybersecurity, and building happy and productive technical teams.</p><p><a href=/about>about</a> - <a href=mailto:hello@victoria.dev>email</a> - <a href=https://github.com/victoriadrake>github</a> - <a href=https://twitter.com/victoriadotdev>twitter</a> - <a href=https://www.linkedin.com/in/victoriadotdev/>linkedin</a></p></div></footer></main><script src=/js/webmention.min.js data-wordcount=42 async></script><nav aria-label="Victoria.dev menu for mobile" id=menu-mobile><ul role=menubar><li role=none class=menu-item><a role=menuitem href=/><img src=/img/bookmark.svg alt="home page icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/blog/><img src=/img/quote.svg alt="blog icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/about/><img src=/img/profile.svg alt="about page icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/coffee/><img src=/img/coffee.svg alt="coffee icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/bookshelf/><img src=/img/book.svg alt="bookshelf icon" height=18px class=filter-icon></a></li></ul></nav></body></html>