<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Victoria Drake, Director of Engineering, is building better cybersecurity and happy and productive technical teams."><title>A coffee-break introduction to time complexity of algorithms | victoria.dev</title><link href=https://github.com/victoriadrake rel=me><link rel=authorization_endpoint href=https://indieauth.com/auth><link rel=token_endpoint href=https://tokens.indieauth.com/token><link rel=webmention href=https://webmention.io/victoria.dev/webmention><link rel=pingback href=https://webmention.io/victoria.dev/xmlrpc><link rel=feed href=https://victoria.dev/neofeed><script async defer data-domain=victoria.dev src=https://p.victoria.dev/js/index.js></script><meta name=monetization content="$ilp.uphold.com/pBRfRwg2EJAe"><meta property="og:title" content="A coffee-break introduction to time complexity of algorithms - victoria.dev"><meta property="og:type" content="website"><meta property="og:description" content="A groundwork understanding of algorithm time complexity in about fifteen minutes."><meta property="og:url" content="https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/"><meta property="og:site_name" content="victoria.dev"><meta property="og:image" content="https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/cover_wibbly.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="A coffee-break introduction to time complexity of algorithms"><meta name=twitter:image content="https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/cover_wibbly.png"><meta name=twitter:description content="A groundwork understanding of algorithm time complexity in about fifteen minutes."><link rel="shortcut icon" href=/img/favicon.ico><link rel=stylesheet href=/css/main.min.4c13cca18828b7ff25325d6765a13a7804155171679a73a19390bb401cea9c1c.css integrity="sha256-TBPMoYgot/8lMl1nZaE6eAQVUXFnmnOhk5C7QBzqnBw=" media=screen></head><body><header role=banner><nav aria-label="Victoria.dev main menu" id=menu><ul role=menubar><li role=none class=menu-item><a role=menuitem href=/><img src=/img/bookmark.svg alt="home page icon" height=18px class=filter-icon> hi</a></li><li role=none class=menu-item><a role=menuitem href=/blog/><img src=/img/quote.svg alt="blog icon" height=18px class=filter-icon> blog</a></li><li role=none class=menu-item><a role=menuitem href=/about/><img src=/img/profile.svg alt="about page icon" height=18px class=filter-icon> about</a></li><li role=none class=menu-item><a role=menuitem href=/coffee/><img src=/img/coffee.svg alt="coffee icon" height=18px class=filter-icon> buy me coffee</a></li><li role=none class=menu-item><a role=menuitem href=/bookshelf/><img src=/img/book.svg alt="bookshelf icon" height=18px class=filter-icon> bookshelf</a></li><li role=none class=menu-item><a role=menuitem id=rss href=https://victoria.dev/index.xml rel=alternate type=application/rss+xml title="RSS for A coffee-break introduction to time complexity of algorithms"><img src=/img/rss.svg alt="RSS icon" height=18px class=filter-icon> rss</a></li></ul></nav></header><main aria-role=main><div class=container><div id=cover-image><img src=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/cover_wibbly.png alt="cover image"></div><article><h1>A coffee-break introduction to time complexity of algorithms</h1><p class=subtitle>A groundwork understanding of algorithm time complexity in about fifteen minutes.</p><span><a class="tag button" href=/tags/algorithms/>algorithms
</a>&nbsp;
<a class="tag button" href=/tags/computing/>computing
</a>&nbsp;
<a class="tag button" href=/tags/go/>go
</a>&nbsp;</span><p class=metadata id=date><time><a class="u-url dt-published" href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/>May 30, 2018</a></time>
<span class=dt-updated>&nbsp;
<em>Updated: Apr 23, 2021</em></span>
<span>☕️ ☕️ ☕️&nbsp;16 min read</span></p></p><div class=toc-dropdown><input type=checkbox id=toc-toggle>
<label for=toc-toggle id=toggle><p class=toc-title><span class=toc-dropdown-icon><img src=/img/anchor.svg height=18px class=filter-icon></span>
Jump to section...</p></label><nav id=TableOfContents><ul><li><a href=#what-is-time-complexity-anyway>What is &ldquo;time complexity&rdquo; anyway</a></li><li><a href=#determining-time-complexity>Determining time complexity</a></li><li><a href=#polynomial-time-complexity>Polynomial time complexity</a><ul><li><a href=#constant>Constant</a></li><li><a href=#linear>Linear</a></li><li><a href=#quadratic>Quadratic</a></li><li><a href=#cubic>Cubic</a></li><li><a href=#logarithmic>Logarithmic</a></li><li><a href=#quasilinear>Quasilinear</a></li><li><a href=#non-polynomial-time-complexity>Non-polynomial time complexity</a></li><li><a href=#factorial>Factorial</a></li><li><a href=#exponential>Exponential</a></li><li><a href=#recursion-time-complexity>Recursion time complexity</a></li><li><a href=#worst-case-time-complexity>Worst case time complexity</a></li></ul></li><li><a href=#p-vs-np-np-complete-and-np-hard>P vs NP, NP-complete, and NP-hard</a></li><li><a href=#approximate-the-efficiency-of-an-algorithm-before-you-write-the-code>Approximate the efficiency of an algorithm before you write the code</a></li><li><a href=#improve-time-complexity-of-existing-code>Improve time complexity of existing code</a></li><li><a href=#sources>Sources</a></li></ul></nav></div><div class=page-separator><hr></div><div class="markdown e-content"><p>Just like writing your very first <code>for</code> loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation - before even running a single line of code.</p><p>The fundamental concepts of complexity analysis are well worth studying. You&rsquo;ll be able to better understand how the code you&rsquo;re writing will interact with the program&rsquo;s input, and as a result, you&rsquo;ll spend a lot less wasted time writing slow and problematic code. It won&rsquo;t take long to go over all you need to know in order to start writing more efficient programs - in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that&rsquo;s your thing) and I&rsquo;ll take you through it before your coffee break is over. Go ahead, I&rsquo;ll wait.</p><p>All set? Let&rsquo;s do it!</p><h2 id=what-is-time-complexity-anyway class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#what-is-time-complexity-anyway>What is &ldquo;time complexity&rdquo; anyway</a></h2><p>The time complexity of an algorithm is an <strong>approximation</strong> of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats; I&rsquo;ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.</p><p>We write about time complexity using <a href=https://en.wikipedia.org/wiki/Big_O_notation>Big O notation</a>, which looks something like <em>O</em>(<em>n</em>). There&rsquo;s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm&rsquo;s approximate run time in the <strong>worst case</strong>, or in other words, its upper bound.<sup>[<a href=#sources>2</a>]</sup> It is inherently relative and comparative.<sup>[<a href=#sources>3</a>]</sup> We&rsquo;re describing the algorithm&rsquo;s efficiency relative to the increasing size of its input data, <em>n</em>. If the input is a string, then <em>n</em> is the length of the string. If it&rsquo;s a list of integers, <em>n</em> is the length of the list.</p><p>It&rsquo;s easiest to picture what Big O notation represents with a graph:</p><figure class=screenshot><img src=graph.png alt="A graph showing different classes of time complexity"><figcaption><p>Lines made with the very excellent Desmos graph calculator. You can <a href=https://www.desmos.com/calculator/xpfyjl1lbn>play with this graph here</a>.</p></figcaption></figure><p>Here are the main important points to remember as you read the rest of this article:</p><ul><li>Time complexity is an approximation</li><li>An algorithm&rsquo;s time complexity approximates its worst case run time</li></ul><h2 id=determining-time-complexity class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#determining-time-complexity>Determining time complexity</a></h2><p>There are different classes of complexity that we can use to quickly understand an algorithm. I&rsquo;ll illustrate some of these classes using nested loops and other examples.</p><h2 id=polynomial-time-complexity class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#polynomial-time-complexity>Polynomial time complexity</a></h2><p>A <strong>polynomial</strong>, from the Greek <em>poly</em> meaning &ldquo;many,&rdquo; and Latin <em>nomen</em> meaning &ldquo;name,&rdquo; describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power.<sup>[<a href=#sources>4</a>]</sup> That&rsquo;s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:</p><p><img src=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/polynomial.png alt="A polynomial example"></p><p>The below classes describe polynomial algorithms. Some have food examples.</p><h3 id=constant class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#constant>Constant</a></h3><p>A <strong>constant time</strong> algorithm doesn&rsquo;t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of <em>O</em>(1).</p><figure class=screenshot><img src=graph%281%29.png alt="A graph showing constant time complexity."></figure><p>Here&rsquo;s one example of a constant algorithm that takes the first item in a slice.</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>takeCupcake</span><span class=p>(</span><span class=nx>cupcakes</span> <span class=p>[]</span><span class=kt>int</span><span class=p>)</span> <span class=kt>int</span> <span class=p>{</span>
    <span class=k>return</span> <span class=nx>cupcakes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<span class=p>}</span>
</code></pre></div><figure><img src=cupcakes.png alt="Types of cupcakes"><figcaption><p>Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and wibbly wobbly, timey wimey cupcake.</p></figcaption></figure><p>With this constant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.</p><h3 id=linear class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#linear>Linear</a></h3><p>The running duration of a <strong>linear</strong> algorithm is constant. It will process the input in <em>n</em> number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.</p><figure class=screenshot><img src=graph%28n%29.png alt="A graph showing linear time complexity."></figure><p>Here&rsquo;s an example of code with time complexity of <em>O</em>(<em>n</em>):</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>eatChips</span><span class=p>(</span><span class=nx>bowlOfChips</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>chip</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>chip</span> <span class=o>&lt;=</span> <span class=nx>bowlOfChips</span><span class=p>;</span> <span class=nx>chip</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// dip chip
</span><span class=c1></span> <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>Here&rsquo;s another example of code with time complexity of <em>O</em>(<em>n</em>):</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>eatChips</span><span class=p>(</span><span class=nx>bowlOfChips</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>chip</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>chip</span> <span class=o>&lt;=</span> <span class=nx>bowlOfChips</span><span class=p>;</span> <span class=nx>chip</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// double dip chip
</span><span class=c1></span> <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>It doesn&rsquo;t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of <em>n</em>, and thus can be described as linear.</p><figure><img src=dip.png alt="Lifeguard MIQ the chip says no double dipping"><figcaption><p>Don&rsquo;t double dip in a shared bowl.</p></figcaption></figure><h3 id=quadratic class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#quadratic>Quadratic</a></h3><figure class=screenshot><img src=graph%28n2%29.png alt="A graph showing quadratic time complexity"></figure><p>Now here&rsquo;s an example of code with time complexity of <em>O</em>(<em>n</em><sup>2</sup>):</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>pizzaDelivery</span><span class=p>(</span><span class=nx>pizzas</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>pizza</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>pizza</span> <span class=o>&lt;=</span> <span class=nx>pizzas</span><span class=p>;</span> <span class=nx>pizza</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// slice pizza
</span><span class=c1></span>  <span class=k>for</span> <span class=nx>slice</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>slice</span> <span class=o>&lt;=</span> <span class=nx>pizza</span><span class=p>;</span> <span class=nx>slice</span><span class=o>++</span> <span class=p>{</span>
   <span class=c1>// eat slice of pizza
</span><span class=c1></span>  <span class=p>}</span>
 <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>Because there are two nested loops, or nested linear operations, the algorithm process the input <em>n</em><sup>2</sup> times.</p><h3 id=cubic class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#cubic>Cubic</a></h3><figure class=screenshot><img src=graph%28n3%29.png alt="A graph showing cubic time complexity"></figure><p>Extending on the previous example, this code with three nested loops has time complexity of <em>O</em>(<em>n</em><sup>3</sup>):</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>pizzaDelivery</span><span class=p>(</span><span class=nx>boxesDelivered</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>pizzaBox</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>pizzaBox</span> <span class=o>&lt;=</span> <span class=nx>boxesDelivered</span><span class=p>;</span> <span class=nx>pizzaBox</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// open box
</span><span class=c1></span>  <span class=k>for</span> <span class=nx>pizza</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>pizza</span> <span class=o>&lt;=</span> <span class=nx>pizzaBox</span><span class=p>;</span> <span class=nx>pizza</span><span class=o>++</span> <span class=p>{</span>
   <span class=c1>// slice pizza
</span><span class=c1></span>   <span class=k>for</span> <span class=nx>slice</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>slice</span> <span class=o>&lt;=</span> <span class=nx>pizza</span><span class=p>;</span> <span class=nx>slice</span><span class=o>++</span> <span class=p>{</span>
    <span class=c1>// eat slice of pizza
</span><span class=c1></span>   <span class=p>}</span>
  <span class=p>}</span>
 <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><figure><img src=unsliced.png alt="A pizza pie in a box with a pizza slicer dependency"><figcaption><p>Seriously though, who delivers unsliced pizza??</p></figcaption></figure><h3 id=logarithmic class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#logarithmic>Logarithmic</a></h3><p>A <strong>logarithmic</strong> algorithm is one that reduces the size of the input at every step.
We denote this time complexity as <em>O</em>(log <em>n</em>), where <strong>log</strong>, the logarithm function, is this shape:</p><figure class=screenshot><img src=graph%28logn%29.png alt="A graph showing logarithmic time complexity"></figure><p>One example of this is a <a href=https://en.wikipedia.org/wiki/Binary_search_algorithm>binary search algorithm</a> that finds the position of an element within a sorted array. Here&rsquo;s how it would work, assuming we&rsquo;re trying to find the element <em>x</em>:</p><ol><li>If <em>x</em> matches the middle element <em>m</em> of the array, return the position of <em>m</em></li><li>If <em>x</em> doesn&rsquo;t match <em>m</em>, see if <em>m</em> is larger or smaller than <em>x</em><ul><li>If larger, discard all array items greater than <em>m</em></li><li>If smaller, discard all array items smaller than <em>m</em></li></ul></li><li>Continue by repeating steps 1 and 2 on the remaining array until <em>x</em> is found</li></ol><p>I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author&rsquo;s last name and you want to find &ldquo;Terry Pratchett,&rdquo; you know you need to look for the &ldquo;P&rdquo; section.</p><p>You can approach the shelf at any point along the aisle and look at the author&rsquo;s last name there. If you&rsquo;re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before &ldquo;G&rdquo; in the alphabet happen to be &ldquo;P.&rdquo; You would then move down the aisle to the right any amount, and repeat this process until you&rsquo;ve found the Terry Pratchett section, which should be rather sizable if you&rsquo;re at any decent bookstore because wow did he write a lot of books.</p><h3 id=quasilinear class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#quasilinear>Quasilinear</a></h3><figure class=screenshot><img src=graph%28nlogn%29.png alt="A graph showing quasilinear time complexity"></figure><p>Often seen with sorting algorithms, the time complexity <em>O</em>(<em>n</em> log <em>n</em>) can describe a data structure where each operation takes <em>O</em>(log <em>n</em>) time. One example of this is <a href=https://en.wikipedia.org/wiki/Quicksort>quick sort</a>, a divide-and-conquer algorithm.</p><p>Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It&rsquo;s faster if you split up the cards and get five friends to help you.</p><h3 id=non-polynomial-time-complexity class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#non-polynomial-time-complexity>Non-polynomial time complexity</a></h3><p>The below classes of algorithms are non-polynomial.</p><h3 id=factorial class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#factorial>Factorial</a></h3><figure class=screenshot><img src=graph%28nfac%29.png alt="A graph showing factorial time complexity"></figure><p>An algorithm with time complexity <em>O</em>(<em>n</em>!) often iterates through all permutations of the input elements. One common example is a <a href=https://en.wikipedia.org/wiki/Brute-force_search>brute-force search</a> seen in the <a href=https://en.wikipedia.org/wiki/Travelling_salesman_problem#Computing_a_solution>travelling salesman problem</a>. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.</p><h3 id=exponential class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#exponential>Exponential</a></h3><p>An <strong>exponential</strong> algorithm often also iterates through all subsets of the input elements. It is denoted <em>O</em>(2<sup><em>n</em></sup>) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.</p><figure class=screenshot><img src=graph%282n%29.png alt="A graph showing exponential time complexity"></figure><p>In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.</p><p>There are further time complexity classes less commonly seen that I won&rsquo;t cover here, but you can read about these and find examples in <a href=https://en.wikipedia.org/wiki/Time_complexity#Table_of_common_time_complexities>this handy table</a>.</p><h3 id=recursion-time-complexity class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#recursion-time-complexity>Recursion time complexity</a></h3><p>As I described in my article <a href=/blog/understanding-array.prototype.reduce-and-recursion-using-apple-pie/>explaining recursion using apple pie</a>, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it&rsquo;s the product of the number of times the function runs and a single execution&rsquo;s time complexity.</p><p>Here&rsquo;s a recursive function that eats pies until no pies are left:</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>eatPies</span><span class=p>(</span><span class=nx>pies</span> <span class=kt>int</span><span class=p>)</span> <span class=kt>int</span> <span class=p>{</span>
 <span class=k>if</span> <span class=nx>pies</span> <span class=o>==</span> <span class=mi>0</span> <span class=p>{</span>
  <span class=k>return</span> <span class=nx>pies</span>
 <span class=p>}</span>
 <span class=k>return</span> <span class=nf>eatPies</span><span class=p>(</span><span class=nx>pies</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.</p><p>The initial number of pies could be any number, and we need to process all of them, so we can describe the input as <em>n</em>. Thus, the time complexity of this recursive function is the product <em>O</em>(<em>n</em>).</p><figure><img src=piespile.png alt="A pile of pizza boxes with pies to be eaten"><figcaption><p>This function&rsquo;s return value is zero, plus some indigestion.</p></figcaption></figure><h3 id=worst-case-time-complexity class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#worst-case-time-complexity>Worst case time complexity</a></h3><p>So far, we&rsquo;ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?</p><p>Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm&rsquo;s run time.</p><p>Say we have a program for an office party. If our program looks like this:</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kn>package</span> <span class=nx>main</span>

<span class=kn>import</span> <span class=s>&#34;fmt&#34;</span>

<span class=kd>func</span> <span class=nf>takeCupcake</span><span class=p>(</span><span class=nx>cupcakes</span> <span class=p>[]</span><span class=kt>int</span><span class=p>)</span> <span class=kt>int</span> <span class=p>{</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Have cupcake number&#34;</span><span class=p>,</span><span class=nx>cupcakes</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
 <span class=k>return</span> <span class=nx>cupcakes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
<span class=p>}</span>

<span class=kd>func</span> <span class=nf>eatChips</span><span class=p>(</span><span class=nx>bowlOfChips</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Have some chips!&#34;</span><span class=p>)</span>
 <span class=k>for</span> <span class=nx>chip</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>chip</span> <span class=o>&lt;=</span> <span class=nx>bowlOfChips</span><span class=p>;</span> <span class=nx>chip</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// dip chip
</span><span class=c1></span> <span class=p>}</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;No more chips.&#34;</span><span class=p>)</span>
<span class=p>}</span>

<span class=kd>func</span> <span class=nf>pizzaDelivery</span><span class=p>(</span><span class=nx>boxesDelivered</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Pizza is here!&#34;</span><span class=p>)</span>
 <span class=k>for</span> <span class=nx>pizzaBox</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>pizzaBox</span> <span class=o>&lt;=</span> <span class=nx>boxesDelivered</span><span class=p>;</span> <span class=nx>pizzaBox</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// open box
</span><span class=c1></span>  <span class=k>for</span> <span class=nx>pizza</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>pizza</span> <span class=o>&lt;=</span> <span class=nx>pizzaBox</span><span class=p>;</span> <span class=nx>pizza</span><span class=o>++</span> <span class=p>{</span>
   <span class=c1>// slice pizza
</span><span class=c1></span>   <span class=k>for</span> <span class=nx>slice</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>slice</span> <span class=o>&lt;=</span> <span class=nx>pizza</span><span class=p>;</span> <span class=nx>slice</span><span class=o>++</span> <span class=p>{</span>
    <span class=c1>// eat slice of pizza
</span><span class=c1></span>   <span class=p>}</span>
  <span class=p>}</span>
 <span class=p>}</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Pizza is gone.&#34;</span><span class=p>)</span>
<span class=p>}</span>

<span class=kd>func</span> <span class=nf>eatPies</span><span class=p>(</span><span class=nx>pies</span> <span class=kt>int</span><span class=p>)</span> <span class=kt>int</span> <span class=p>{</span>
 <span class=k>if</span> <span class=nx>pies</span> <span class=o>==</span> <span class=mi>0</span> <span class=p>{</span>
  <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Someone ate all the pies!&#34;</span><span class=p>)</span>
  <span class=k>return</span> <span class=nx>pies</span>
 <span class=p>}</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Eating pie...&#34;</span><span class=p>)</span>
 <span class=k>return</span> <span class=nf>eatPies</span><span class=p>(</span><span class=nx>pies</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>}</span>

<span class=kd>func</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
 <span class=nf>takeCupcake</span><span class=p>([]</span><span class=kt>int</span><span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>})</span>
 <span class=nf>eatChips</span><span class=p>(</span><span class=mi>23</span><span class=p>)</span>
 <span class=nf>pizzaDelivery</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
 <span class=nf>eatPies</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>
 <span class=nx>fmt</span><span class=p>.</span><span class=nf>Println</span><span class=p>(</span><span class=s>&#34;Food gone. Back to work!&#34;</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we&rsquo;ve already seen, with the following time complexity classes:</p><table><thead><tr><th>Function</th><th>Class</th><th>Big O</th></tr></thead><tbody><tr><td><code>takeCupcake</code></td><td>constant</td><td><em>O</em>(1)</td></tr><tr><td><code>eatChips</code></td><td>linear</td><td><em>O</em>(<em>n</em>)</td></tr><tr><td><code>pizzaDelivery</code></td><td>cubic</td><td><em>O</em>(<em>n</em><sup>3</sup>)</td></tr><tr><td><code>eatPies</code></td><td>linear (recursive)</td><td><em>O</em>(<em>n</em>)</td></tr></tbody></table><p>To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity <em>O</em>(<em>n</em><sup>3</sup>).</p><p>Here&rsquo;s the office party soundtrack, just for fun.</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>Have cupcake number <span class=m>1</span>
Have some chips!
No more chips.
Pizza is here!
Pizza is gone.
Eating pie...
Eating pie...
Eating pie...
Someone ate all the pies!
Food gone. Back to work!
</code></pre></div><h2 id=p-vs-np-np-complete-and-np-hard class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#p-vs-np-np-complete-and-np-hard>P vs NP, NP-complete, and NP-hard</a></h2><p>You may come across these terms in your explorations of time complexity. Informally, <strong>P</strong> (for Polynomial time), is a class of problems that is quick to solve. <strong>NP</strong>, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called <strong>NP-complete</strong>, for which no fast solution is known.<sup>[<a href=#sources>5</a>]</sup> Outside of NP but still including NP-complete is yet another class called <strong>NP-hard</strong>, which includes problems that no one has been able to verifiably solve with polynomial algorithms.<sup>[<a href=#sources>6</a>]</sup></p><figure class=screenshot><img src=pnpeuler.svg alt="Euler diagram"><figcaption><p>P vs NP Euler diagram, <a href="https://commons.wikimedia.org/w/index.php?curid=3532181">by Behnam Esfahbod, CC BY-SA 3.0</a></p></figcaption></figure><p><a href=https://en.wikipedia.org/wiki/P_versus_NP_problem>P versus NP</a> is an unsolved, open question in computer science.</p><p>Anyway, you don&rsquo;t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They&rsquo;re a whole other Pandora&rsquo;s box.</p><h2 id=approximate-the-efficiency-of-an-algorithm-before-you-write-the-code class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#approximate-the-efficiency-of-an-algorithm-before-you-write-the-code>Approximate the efficiency of an algorithm before you write the code</a></h2><p>So far, we&rsquo;ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we&rsquo;ve written any code to evaluate?</p><p>By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second.<sup>[<a href=#sources>1</a>]</sup> The following table from the <a href=#sources>Competitive Programmer&rsquo;s Handbook</a> offers some estimates on required time complexity to process the respective input size in a time limit of one second.</p><table><thead><tr><th>Input size</th><th>Required time complexity for 1s processing time</th></tr></thead><tbody><tr><td>n ≤ 10</td><td><em>O</em>(<em>n</em>!)</td></tr><tr><td>n ≤ 20</td><td><em>O</em>(2<sup><em>n</em></sup>)</td></tr><tr><td>n ≤ 500</td><td><em>O</em>(<em>n</em><sup>3</sup>)</td></tr><tr><td>n ≤ 5000</td><td><em>O</em>(<em>n</em><sup>2</sup>)</td></tr><tr><td>n ≤ 10<sup>6</sup></td><td><em>O</em>(<em>n</em> log <em>n</em>) or <em>O</em>(<em>n</em>)</td></tr><tr><td>n is large</td><td><em>O</em>(1) or <em>O</em>(log <em>n</em>)</td></tr></tbody></table><p>Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn&rsquo;t account for <strong>constant factors</strong>. Here&rsquo;s some code to illustrate.</p><p>The following two algorithms both have <em>O</em>(<em>n</em>) time complexity.</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>makeCoffee</span><span class=p>(</span><span class=nx>scoops</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>scoop</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>scoop</span> <span class=o>&lt;=</span> <span class=nx>scoops</span><span class=p>;</span> <span class=nx>scoop</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// add instant coffee
</span><span class=c1></span> <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>makeStrongCoffee</span><span class=p>(</span><span class=nx>scoops</span> <span class=kt>int</span><span class=p>)</span> <span class=p>{</span>
 <span class=k>for</span> <span class=nx>scoop</span> <span class=o>:=</span> <span class=mi>0</span><span class=p>;</span> <span class=nx>scoop</span> <span class=o>&lt;=</span> <span class=mi>3</span><span class=o>*</span><span class=nx>scoops</span><span class=p>;</span> <span class=nx>scoop</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// add instant coffee
</span><span class=c1></span> <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let&rsquo;s ask both these functions for a cup of coffee with a million scoops.</p><p>Here&rsquo;s the output of the Go test:</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh>Benchmark_makeCoffee-4          <span class=m>1000000000</span>               0.29 ns/op
Benchmark_makeStrongCoffee-4    <span class=m>1000000000</span>               0.86 ns/op
</code></pre></div><p>Our first function, <code>makeCoffee</code>, completed in an average 0.29 nanoseconds. Our second function, <code>makeStrongCoffee</code>, completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took near three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn&rsquo;t tell you this, since the constant factor of the tripled scoops isn&rsquo;t accounted for.</p><h2 id=improve-time-complexity-of-existing-code class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#improve-time-complexity-of-existing-code>Improve time complexity of existing code</a></h2><p>Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I&rsquo;ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.</p><p>Let&rsquo;s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an <code>int</code> > 0:</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=nx>diners</span> <span class=o>:=</span> <span class=p>[]</span><span class=kt>int</span><span class=p>{</span><span class=mi>2</span><span class=p>,</span> <span class=mi>88</span><span class=p>,</span> <span class=mi>87</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>56</span><span class=p>}</span>
</code></pre></div><p>Unfortunately, we&rsquo;re bootstrapped and there are only three forks to go around. Since we&rsquo;re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they&rsquo;ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we&rsquo;ll have to make do with everybody jumbled about.</p><p>Without sorting the list of diners, return the three largest integers in the slice.</p><p>Here&rsquo;s a function that solves this problem and has <em>O</em>(<em>n</em><sup>2</sup>) time complexity:</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>giveForks</span><span class=p>(</span><span class=nx>diners</span> <span class=p>[]</span><span class=kt>int</span><span class=p>)</span> <span class=p>[]</span><span class=kt>int</span> <span class=p>{</span>
 <span class=c1>// make a slice to store diners who will receive forks
</span><span class=c1></span> <span class=kd>var</span> <span class=nx>withForks</span> <span class=p>[]</span><span class=kt>int</span>
 <span class=c1>// loop over three forks
</span><span class=c1></span> <span class=k>for</span> <span class=nx>i</span> <span class=o>:=</span> <span class=mi>1</span><span class=p>;</span> <span class=nx>i</span> <span class=o>&lt;=</span> <span class=mi>3</span><span class=p>;</span> <span class=nx>i</span><span class=o>++</span> <span class=p>{</span>
  <span class=c1>// variables to keep track of the highest integer and where it is
</span><span class=c1></span>  <span class=kd>var</span> <span class=nx>max</span><span class=p>,</span> <span class=nx>maxIndex</span> <span class=kt>int</span>
  <span class=c1>// loop over the diners slice
</span><span class=c1></span>  <span class=k>for</span> <span class=nx>n</span> <span class=o>:=</span> <span class=k>range</span> <span class=nx>diners</span> <span class=p>{</span>
   <span class=c1>// if this integer is higher than max, update max and maxIndex
</span><span class=c1></span>   <span class=k>if</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>n</span><span class=p>]</span> <span class=p>&gt;</span> <span class=nx>max</span> <span class=p>{</span>
    <span class=nx>max</span> <span class=p>=</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>n</span><span class=p>]</span>
    <span class=nx>maxIndex</span> <span class=p>=</span> <span class=nx>n</span>
   <span class=p>}</span>
  <span class=p>}</span>
  <span class=c1>// remove the highest integer from the diners slice for the next loop
</span><span class=c1></span>  <span class=nx>diners</span> <span class=p>=</span> <span class=nb>append</span><span class=p>(</span><span class=nx>diners</span><span class=p>[:</span><span class=nx>maxIndex</span><span class=p>],</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>maxIndex</span><span class=o>+</span><span class=mi>1</span><span class=p>:]</span><span class=o>...</span><span class=p>)</span>
  <span class=c1>// keep track of who gets a fork
</span><span class=c1></span>  <span class=nx>withForks</span> <span class=p>=</span> <span class=nb>append</span><span class=p>(</span><span class=nx>withForks</span><span class=p>,</span> <span class=nx>max</span><span class=p>)</span>
 <span class=p>}</span>
 <span class=k>return</span> <span class=nx>withForks</span>
<span class=p>}</span>
</code></pre></div><p>This program works, and eventually returns diners <code>[88 87 56]</code>. Everyone gets a little impatient while it&rsquo;s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie&rsquo;s getting cold. How could we improve it?</p><p>By thinking about our approach in a slightly different way, we can refactor this program to have <em>O</em>(<em>n</em>) time complexity:</p><div class=highlight><pre class=chroma><code class=language-go data-lang=go><span class=kd>func</span> <span class=nf>giveForks</span><span class=p>(</span><span class=nx>diners</span> <span class=p>[]</span><span class=kt>int</span><span class=p>)</span> <span class=p>[]</span><span class=kt>int</span> <span class=p>{</span>
 <span class=c1>// make a slice to store diners who will receive forks
</span><span class=c1></span> <span class=kd>var</span> <span class=nx>withForks</span> <span class=p>[]</span><span class=kt>int</span>
 <span class=c1>// create variables for each fork
</span><span class=c1></span> <span class=kd>var</span> <span class=nx>first</span><span class=p>,</span> <span class=nx>second</span><span class=p>,</span> <span class=nx>third</span> <span class=kt>int</span>
 <span class=c1>// loop over the diners
</span><span class=c1></span> <span class=k>for</span> <span class=nx>i</span> <span class=o>:=</span> <span class=k>range</span> <span class=nx>diners</span> <span class=p>{</span>
  <span class=c1>// assign the forks
</span><span class=c1></span>  <span class=k>if</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span> <span class=p>&gt;</span> <span class=nx>first</span> <span class=p>{</span>
   <span class=nx>third</span> <span class=p>=</span> <span class=nx>second</span>
   <span class=nx>second</span> <span class=p>=</span> <span class=nx>first</span>
   <span class=nx>first</span> <span class=p>=</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span>
  <span class=p>}</span> <span class=k>else</span> <span class=k>if</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span> <span class=p>&gt;</span> <span class=nx>second</span> <span class=p>{</span>
   <span class=nx>third</span> <span class=p>=</span> <span class=nx>second</span>
   <span class=nx>second</span> <span class=p>=</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span>
  <span class=p>}</span> <span class=k>else</span> <span class=k>if</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span> <span class=p>&gt;</span> <span class=nx>third</span> <span class=p>{</span>
   <span class=nx>third</span> <span class=p>=</span> <span class=nx>diners</span><span class=p>[</span><span class=nx>i</span><span class=p>]</span>
  <span class=p>}</span>
 <span class=p>}</span>
 <span class=c1>// list the final result of who gets a fork
</span><span class=c1></span> <span class=nx>withForks</span> <span class=p>=</span> <span class=nb>append</span><span class=p>(</span><span class=nx>withForks</span><span class=p>,</span> <span class=nx>first</span><span class=p>,</span> <span class=nx>second</span><span class=p>,</span> <span class=nx>third</span><span class=p>)</span>
 <span class=k>return</span> <span class=nx>withForks</span>
<span class=p>}</span>
</code></pre></div><p>Here&rsquo;s how the new program works:</p><p>Initially, diner <code>2</code> (the first in the list) is assigned the <code>first</code> fork. The other forks remain unassigned.</p><p>Then, diner <code>88</code> is assigned the first fork instead. Diner <code>2</code> gets the <code>second</code> one.</p><p>Diner <code>87</code> isn&rsquo;t greater than <code>first</code> which is currently <code>88</code>, but it is greater than <code>2</code> who has the <code>second</code> fork. So, the <code>second</code> fork goes to <code>87</code>. Diner <code>2</code> gets the <code>third</code> fork.</p><p>Continuing in this violent and rapid fork exchange, diner <code>16</code> is then assigned the <code>third</code> fork instead of <code>2</code>, and so on.</p><p>We can add a print statement in the loop to see how the fork assignments play out:</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh><span class=m>0</span> <span class=m>0</span> <span class=m>0</span>
<span class=m>2</span> <span class=m>0</span> <span class=m>0</span>
<span class=m>88</span> <span class=m>2</span> <span class=m>0</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>2</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>16</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>42</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>42</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>42</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>42</span>
<span class=m>88</span> <span class=m>87</span> <span class=m>43</span>
<span class=o>[</span><span class=m>88</span> <span class=m>87</span> 56<span class=o>]</span>
</code></pre></div><p>This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.</p><p>As you can see, with a little change in perspective and some refactoring, we&rsquo;ve made this simple bit of code faster and more efficient.</p><p>Well, it looks like our fifteen minute coffee break is up! I hope I&rsquo;ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)</p><h2 id=sources class=anchor-link><a href=https://victoria.dev/blog/a-coffee-break-introduction-to-time-complexity-of-algorithms/#sources>Sources</a></h2><p>&ldquo;If I have seen further it is by standing on the shoulders of Giants.&rdquo; &ndash;Isaac Newton, 1675</p><ol><li>Antti Laaksonen. <em><a href=https://cses.fi/book.pdf>Competitive Programmer&rsquo;s Handbook (pdf)</a>,</em> 2017</li><li>Wikipedia: <a href=https://en.wikipedia.org/wiki/Big_O_notation>Big O notation</a></li><li>StackOverflow: <a href=https://stackoverflow.com/a/487278>What is a plain English explanation of “Big O” notation?</a></li><li>Wikipedia: <a href=https://en.wikipedia.org/wiki/Polynomial>Polynomial</a></li><li>Wikipedia: <a href=https://en.wikipedia.org/wiki/NP-completeness>NP-completeness</a></li><li>Wikipedia: <a href=https://en.wikipedia.org/wiki/NP-hardness>NP-hardness</a></li><li><a href=https://www.desmos.com/>Desmos graph calculator</a></li></ol></div><a class=hidden href=https://brid.gy/publish/twitter></a><a class=hidden href=https://brid.gy/publish/mastodon></a><data class=p-bridgy-omit-link value=false></data></article><div id=up-container><a href=# id=up>&#709;</a></div><div class=page-separator><hr></div><div id=webmentions></div><div class=related><code class=language-sql data-lang=sql>SELECT TOP 3 * FROM Related;</code><ul role=menubar id=article-list><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/knapsack-problem-algorithms-for-my-real-life-carry-on-knapsack/>Knapsack problem algorithms for my real-life carry-on knapsack</a><p class=e-content>Using a greedy algorithm and dynamic programming to pack my full-time nomad travel bag.</p><p class=metadata><a class="tag button" href=/tags/algorithms/>algorithms</a>
☕️ ☕️ ☕️ ☕️
&nbsp;23 min read
<time class="hidden dt-published">2018-05-09 21:00:35 -0400 -0400</time></p></li><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/wpa-key-wpa2-wpa3-and-wep-key-wi-fi-security-explained/>WPA Key, WPA2, WPA3, and WEP Key: Wi-Fi security explained</a><p class=e-content>Which one should you be using? Why Wi-Fi security matters.</p><p class=metadata><a class="tag button" href=/tags/computing/>computing</a>
☕️ ☕️
&nbsp;8 min read
<time class="hidden dt-published">2020-10-19 04:02:27 -0400 -0400</time></p></li><li role=none class=h-entry><p class="p-author h-card hidden">Victoria Drake</p><img class="u-photo hidden" alt="photo of the author" id=author-img src=/img/victoria_headshot.jpg>
<a role=menuitem class="article-link u-url p-name" href=https://victoria.dev/blog/what-is-tls-transport-layer-security-encryption-explained-in-plain-english/>What is TLS? Transport Layer Security encryption explained in plain english</a><p class=e-content>How TLS, digital certificates, and sessions help keep communications secure.</p><p class=metadata><a class="tag button" href=/tags/cybersecurity/>cybersecurity</a>
☕️
&nbsp;5 min read
<time class="hidden dt-published">2020-09-05 04:48:39 -0600 -0600</time></p></li></ul><div class=page-separator><p class=back-link><a href=/blog>&lt;&lt; Back to blog</a></p></div></div></div><footer class=container><div class="markdown bio h-card p-author"><strong><a href=https://victoria.dev/ class="u-url p-name">Victoria Drake</a></strong><figure class="profile title-avatar u-photo"><img src=/img/victoria_headshot.jpg alt="Victoria's headshot"></figure><p>Victoria Drake is a Director of Engineering in Washington, DC. She is a core maintainer and co-author for the Open Web Application Security Project (OWASP) Web Security Testing Guide. She earned the annual Top Contributor award three years in a row from the freeCodeCamp non-profit, and was recognized two years in a row as a Distinguished Author on the DEV.to developer platform. She writes and educates programmers and business leaders about cybersecurity, software development, and building happy and productive technical teams.</p><p><a href=/about>about</a> - <a href=mailto:hello@victoria.dev>email</a> - <a href=https://github.com/victoriadrake>github</a> - <a href=https://twitter.com/victoriadotdev>twitter</a> - <a href=https://www.linkedin.com/in/victoriadotdev/>linkedin</a></p></div></footer></main><script src=/js/webmention.min.js data-wordcount=42 async></script><nav aria-label="Victoria.dev menu for mobile" id=menu-mobile><ul role=menubar><li role=none class=menu-item><a role=menuitem href=/><img src=/img/bookmark.svg alt="home page icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/blog/><img src=/img/quote.svg alt="blog icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/about/><img src=/img/profile.svg alt="about page icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/coffee/><img src=/img/coffee.svg alt="coffee icon" height=18px class=filter-icon></a></li><li role=none class=menu-item><a role=menuitem href=/bookshelf/><img src=/img/book.svg alt="bookshelf icon" height=18px class=filter-icon></a></li></ul></nav></body></html>